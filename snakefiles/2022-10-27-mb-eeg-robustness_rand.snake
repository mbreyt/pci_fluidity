import os, sys
sys.path.append(os.path.join(os.getcwd(), '../utils'))
currentdir = os.path.dirname(os.path.realpath(__file__))
parentdir = os.path.dirname(currentdir)
sys.path.append(parentdir)
import mne
import pci
import numpy as nppd
from scipy.io import loadmat, matlab
import scipy.signal as sig
from itertools import combinations


import scipy.stats as st

output_dir = os.path.join(
        "/Users/martinbreyton/INS_Code/EEG/data/interim/robustness_analysis"
)
data_dir = os.path.join(
        "/Users/martinbreyton/INS_Code/EEG/data/interim/XPK_RsEeg_renamed_smoothed"
)


SUBS = [f's{int(i+1)}' for i in range(5)]
DRUGS = ['XEN', 'PRO', 'KET']
STATES = ['wake', 'anesth']
# thrs = [2.8, 2.9,3.0,3.1, 3.2]
thrs = [3.0]
# LS = [60,120,180, 10000]
LS = [60]
# BINSIZES =[1,2,3]
BINSIZES = [1, 2]
SEEDS = [i for i in range(50)]

rule all:
    input:
        expand(
            os.path.join(output_dir, "rand_stats_{subject}_{drug}_{state}_thr{thr}_L{length}_bin{binsize}_seed{seed}.npz"),
            subject=SUBS,
            drug=DRUGS,
            state=STATES,
            thr=thrs,
            length=LS,
            binsize=BINSIZES,
            seed=SEEDS
        )

rule statistics:
    input:
        expand(
            os.path.join(data_dir, "eeg_psd_{{drug}}_{{state}}_{{subject}}.mat_decim_5.npz"),
            subject=SUBS,
            drug=DRUGS,
            state=STATES
        )
    output:
        expand(
            os.path.join(output_dir, "rand_stats_{{subject}}_{{drug}}_{{state}}_thr{{thr}}_L{{length}}_bin{{binsize}}_seed{{seed}}.npz"),
            subject=SUBS,
            drug=DRUGS,
            state=STATES,
            thr=thrs,
            length=LS,
            binsize=BINSIZES,
            seed=SEEDS
        )
    run:
        thr = float(wildcards.thr)
        length = int(wildcards.length)
        binsize = int(wildcards.binsize)
        file = input[0]
        file = file.split('/')[-1]
        data_file = np.load(input[0], allow_pickle=True)['info'][0]
        ts= np.load(input[0], allow_pickle=True)['data']

        z_scored = st.zscore(ts, axis=1)

        freq = data_file['decim_freq']
        drug = file.split('_')[2]
        state = file.split('_')[3]
        sub = file.split('_')[4].split('.')[0]
        
        Zbin=np.where(np.abs(st.zscore(ts[:,:int(freq)*length], axis=1))>thr,1,0)
        States=Zbin[np.any(Zbin,axis=1)]
        unique_cols = np.unique(States, axis=1)
        np.random.seed(int(wildcards.seed))
        random_start = np.random.randint(0, int(ts.shape[1]//freq)-60)*int(freq)
        print(random_start)
        if length > ts.shape[1]//freq:
            print('Data too short', ts.shape)
            delta = ts.shape[1]%binsize
            avalanches = go_avalanches(ts[:,random_start:int(ts.shape[1]-delta)].T, binsize=binsize, thre=thr)
            print('Start LZ')
            lz = pci.lz_complexity_2D(np.where(np.abs(st.zscore(ts[:,random_start:int(ts.shape[1]-delta)], axis=1))>thr,1,0))
            print('End LZ')
        else:
            avalanches = go_avalanches(ts[:,random_start:random_start+int(freq)*length].T, binsize=binsize, thre=thr)
            print('Start LZ')
            lz = pci.lz_complexity_2D(np.where(np.abs(st.zscore(ts[:,random_start:random_start+int(freq)*length], axis=1))>thr,1,0))
            print('End LZ')
        avals = []
        for j,k in avalanches['ranges']:
            if Zbin[:,j:k].shape[1] < 3:
                continue
            else:
                aval = np.where(np.any(Zbin[:,j:k].squeeze(), axis=1), 1,0)
                avals.append(aval)
        data_dict = {
            'state': state,
            'drug': drug,
            'subject': sub[1],
            'freq': freq,
            'n_states': np.unique(np.stack(avals), axis=1).shape[0],
            'time': ts.shape[1]/freq,
            'lz': lz,
            'bratio': avalanches['bratio'],
            'N_aval': len(avalanches['dur']),
            'avg_dur': np.mean(avalanches['dur']),
            'avg_siz': np.mean(avalanches['siz']),
            'thr': thr,
            'binsize': binsize,
            'length': length
        }
        np.savez(output[0], data=data_dict)





